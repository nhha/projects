---
title: "R Notebook"
output: pdf_notebook
---
```{r}
library(forecast)
```

```{r}
train <- read.csv('/Users/nahyunha/Desktop/TimeSeries/Project/train.csv')
test <- read.csv('/Users/nahyunha/Desktop/TimeSeries/Project/test.csv')
```

train: January 1987 to December 2008 
validation: January 2009 to December 2010 
test: January 2011 to December 2012

```{r}
full_ts <- ts(train, start=c(1987,1), end=c(2010,12), frequency = 12)
train_ts <- ts(train[1:264, ], start=c(1987,1), end=c(2008,12), frequency = 12)
validation_ts <- ts(train[265:288, ], start=c(2009,1), end=c(2010,12), frequency = 12)
```

```{r}
BoxCox.lambda(train_ts[,'Bankruptcy_Rate'])
```
Log transform the bankruptcy rate.

```{r}
plot(train_ts)
```

```{r}
train_ts
```


```{r}
brate <- train_ts[,'Bankruptcy_Rate']
plot(brate)
```
```{r}
acf(log(brate), lag.max = 60)
```


```{r}
plot(log(brate))
```


```{r}
brate.t <- diff(brate)
brate.st <- diff(brate.t, lag=12, differences = 2)
par(mfrow = c(2,1))
acf(brate.st, lag.max = 60)
pacf(brate.st, lag.max = 60)
```

```{r}
tsdiag(auto.arima(brate))
```


Model 1: Additive Holt Winters.
```{r}
m1 <- HoltWinters(x = brate,alpha = 0.2, beta =  0.2, gamma = 0.2, seasonal = "additive") 
par(mfrow = c(3,1))
plot(m1)
plot(full_ts[,'Bankruptcy_Rate'])
plot(forecast(m1, h = 24, level=95))
```

Model 2: Additive Holt Winters with no parameters given. 
```{r}
m2 <- HoltWinters(x = brate, seasonal = "additive") 
par(mfrow = c(3,1))
plot(m2)
plot(full_ts[,'Bankruptcy_Rate'])
plot(forecast(m2, h = 24, level=95))
```

Model 3: Multiplicative Holt Winter.
```{r}
m3 <- HoltWinters(x = brate,alpha = 0.2, beta =  0.2, gamma = 0.2, seasonal = "mult") 
par(mfrow = c(3,1))
plot(m3)
plot(full_ts[,'Bankruptcy_Rate'])
plot(forecast(m3, h = 24, level = 95), ylim=c(0,0.05))
```

Model 4: Multiplicative Holt Winters with no parameters given.
```{r}
m4 <- HoltWinters(x = brate,  seasonal = "mult") 
par(mfrow = c(3,1))
plot(m4)
plot(full_ts[,'Bankruptcy_Rate'])
plot(forecast(m4, h = 24, level = 95),ylim=c(0,0.05))
```

How well does the model fit the data?
```{r}
training_rmse_m1 <- sqrt(mean((brate - m1$fitted)^2))
training_rmse_m2 <- sqrt(mean((brate - m2$fitted)^2))
training_rmse_m3 <- sqrt(mean((brate - m3$fitted)^2))
training_rmse_m4 <- sqrt(mean((brate - m4$fitted)^2))

data.frame("model" = c("add.hw", "add.hw.np", "mult.hw", "mult.hw.np"),
            "goodness_of_fit" = c(training_rmse_m1, training_rmse_m2, training_rmse_m3, training_rmse_m4))
```
The additive models are fitting data better than the multiplicative model.


How well does the model predict the validation data?
```{r}
predicted.m1 <- forecast(m1, h = 24)
predicted.m2 <- forecast(m2, h = 24)
predicted.m3 <- forecast(m3, h = 24)
predicted.m4 <- forecast(m4, h = 24)

rmse_m1 <- sqrt(mean((predicted.m1$mean - validation_ts[,'Bankruptcy_Rate'])^2))
rmse_m2 <- sqrt(mean((predicted.m2$mean - validation_ts[,'Bankruptcy_Rate'])^2))
rmse_m3 <- sqrt(mean((predicted.m3$mean - validation_ts[,'Bankruptcy_Rate'])^2))
rmse_m4 <- sqrt(mean((predicted.m4$mean - validation_ts[,'Bankruptcy_Rate'])^2))


data.frame("model" = c("add.hw", "add.hw.np", "mult.hw", "mult.hw.np"),
            "prediction" = c(rmse_m1, rmse_m2, rmse_m3, rmse_m4))
```
The additive model also does better in terms of prediction.


Working with additive model, let's try tuning the parameter (alpha, beta, gamma).

```{r}
m1.1 <- HoltWinters(x = brate, alpha = 0.1, beta =  0.2, gamma = 0.2, seasonal = "add") 
m1.2 <- HoltWinters(x = brate, alpha = 0.5, beta =  0.2, gamma = 0.2, seasonal = "add") 
m1.3 <- HoltWinters(x = brate, alpha = 0.2, beta =  0.1, gamma = 0.2, seasonal = "add") 
m1.4 <- HoltWinters(x = brate, alpha = 0.2, beta =  0.5, gamma = 0.2, seasonal = "add") 
m1.5 <- HoltWinters(x = brate, alpha = 0.2, beta =  0.2, gamma = 0.5, seasonal = "add") 
m1.6 <- HoltWinters(x = brate, alpha = 0.2, beta =  0.2, gamma = 0.1, seasonal = "add") 
m1.7 <- HoltWinters(x = brate, alpha = 0.2, beta =  0.1, gamma = 0.6, seasonal = "add") 

training_rmse_m1 <- sqrt(mean((brate - m1$fitted)^2))
training_rmse_m1.1 <- sqrt(mean((brate - m1.1$fitted)^2))
training_rmse_m1.2 <- sqrt(mean((brate - m1.2$fitted)^2))
training_rmse_m1.3 <- sqrt(mean((brate - m1.3$fitted)^2))
training_rmse_m1.4 <- sqrt(mean((brate - m1.4$fitted)^2))
training_rmse_m1.5 <- sqrt(mean((brate - m1.5$fitted)^2))
training_rmse_m1.6 <- sqrt(mean((brate - m1.6$fitted)^2))
training_rmse_m1.7 <- sqrt(mean((brate - m1.7$fitted)^2))


data.frame("model" = c("(0.2, 0.2, 0.2)", "(0.1, 0.2, 0.2)", "(0.5, 0.2, 0.2)", "(0.2, 0.1, 0.2)", "(0.2, 0.5, 0.2)", 
                       "(0.2, 0.2, 0.5)", "(0.2, 0.2, 0.1)", "(0.2, 0.1, 0.6)"),
            "goodness_of_fit" = c(training_rmse_m1, training_rmse_m1.1, training_rmse_m1.2, training_rmse_m1.3,
                                  training_rmse_m1.4, training_rmse_m1.5, training_rmse_m1.6, training_rmse_m1.7))


```
Not really that useful (only changes in 4th decimal point). Just choose the model with parameters (0.2, 0.2, 0.2).

