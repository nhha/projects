---
title: "R Notebook"
output: pdf_notebook
---
```{r}
library(forecast)
```

```{r}
train <- read.csv('/Users/nahyunha/Desktop/TimeSeries/Project/train.csv')
test <- read.csv('/Users/nahyunha/Desktop/TimeSeries/Project/test.csv')
```

train: January 1987 to December 2008 
validation: January 2009 to December 2010 
test: January 2011 to December 2012

```{r}
full_ts <- ts(train, start=c(1987,1), end=c(2010,12), frequency = 12)
train_ts <- ts(train[1:264, ], start=c(1987,1), end=c(2008,12), frequency = 12)
validation_ts <- ts(train[265:288, ], start=c(2009,1), end=c(2010,12), frequency = 12)
```

```{r}
BoxCox.lambda(train_ts[,'Bankruptcy_Rate'])
```
Log transform the bankruptcy rate.

```{r}
plot(train_ts)
```

```{r}
brate <- train_ts[,'Bankruptcy_Rate']
plot(brate)

```

```{r}
plot(log(brate))
```

```{r}
acf(log(brate), lag.max = 60)
```


```{r}
plot(log(brate), main='Logged Bankruptcy Rate', ylab = 'Bankruptcy Rate')
```

```{r}
plot(diff(log(brate)), main='Bankruptcy Rate with No Trend', ylab = 'Bankruptcy Rate')
```

```{r}
par(mfrow = c(2,1))
acf(diff(log(brate), max.lag = 60), main = '')
pacf(diff(log(brate), max.lag = 60), main = '')
```


```{r}
brate.t <- diff(brate)
brate.st <- diff(brate.t, lag=12, differences = 2)
par(mfrow = c(2,1))
acf(brate.st, lag.max = 60)
pacf(brate.st, lag.max = 60)
```

```{r}
tsdiag(auto.arima(brate))
```

Model 1: Additive Holt Winters.
```{r}
m1 <- HoltWinters(x = brate, alpha = 0.2, beta =  0.2, gamma = 0.2, seasonal = "additive") 
# par(mfrow = c(3,1))
plot(m1)
par(mfrow = c(2,1))
plot(full_ts[,'Bankruptcy_Rate'], ylab = 'Bankruptcy Rate', main = 'Full Observed Time Series')
plot(forecast(m1, h = 24, level=95), ylab = 'Bankruptcy Rate', xlab='Time')
```


Model 2: Additive Holt Winters with no parameters given. 
```{r}
m2 <- HoltWinters(x = brate, seasonal = "additive") 
par(mfrow = c(3,1))
plot(m2)
plot(full_ts[,'Bankruptcy_Rate'])
plot(forecast(m2, h = 24, level=95))
```

Model 3: Multiplicative Holt Winter.
```{r}
m3 <- HoltWinters(x = brate,alpha = 0.2, beta =  0.2, gamma = 0.2, seasonal = "mult") 
par(mfrow = c(3,1))
plot(m3)
plot(full_ts[,'Bankruptcy_Rate'])
plot(forecast(m3, h = 24, level = 95), ylim=c(0,0.05))
```

Model 4: Multiplicative Holt Winters with no parameters given.
```{r}
m4 <- HoltWinters(x = brate,  seasonal = "mult") 
par(mfrow = c(3,1))
plot(m4)
plot(full_ts[,'Bankruptcy_Rate'])
plot(forecast(m4, h = 24, level = 95))
```

Model 5: Double Exp Smoothing
```{r}
m5 <- HoltWinters(x = brate, alpha = 0.2, beta = 0.2, gamma = F)
par(mfrow = c(3,1))
plot(m5)
plot(full_ts[,'Bankruptcy_Rate'])
plot(forecast(m5, h = 24, level = 95))

```

Model 6: Double Exp Smoothing with no parameters given.
```{r}
m6 <- HoltWinters(x = brate, gamma = F)
par(mfrow = c(3,1))
plot(m6)
plot(full_ts[,'Bankruptcy_Rate'])
plot(forecast(m6, h = 24, level = 95))

```

```{r}
plot(m6)
legend("bottomright", legend = c("Observed", "Fitted"), lty = 1, col = c("black", "red"), cex = 0.7)

```

```{r}
plot(forecast(m6, h = 24, level = 95))
legend("bottomright", legend = c("Observed", "Predicted"), lty = 1, col = c("black", "blue"), cex = 0.7)

```


How well does the model fit the data?
```{r}
# training_rmse_m1 <- sqrt(mean((brate - m1$fitted)^2))
# training_rmse_m2 <- sqrt(mean((brate - m2$fitted)^2))
# training_rmse_m3 <- sqrt(mean((brate - m3$fitted)^2))
# training_rmse_m4 <- sqrt(mean((brate - m4$fitted)^2))
# 
# data.frame("model" = c("add.hw", "add.hw.np", "mult.hw", "mult.hw.np"),
#             "goodness_of_fit" = c(training_rmse_m1, training_rmse_m2, training_rmse_m3, training_rmse_m4))


# training_rse_m1 <- sqrt(sum((brate - m1$fitted)^2))
# training_rse_m2 <- sqrt(sum((brate - m2$fitted)^2))
# training_rse_m3 <- sqrt(sum((brate - m3$fitted)^2))
# training_rse_m4 <- sqrt(sum((brate - m4$fitted)^2))
# training_rse_m5 <- sqrt(sum((brate - m5$fitted)^2))
# training_rse_m6 <- sqrt(sum((brate - m6$fitted)^2))


training_sse_m1 <- m1$SSE
training_sse_m2 <- m2$SSE
training_sse_m5 <- m5$SSE
training_sse_m6 <- m6$SSE
training_sse_m3 <- m3$SSE
training_sse_m4 <- m4$SSE


# data.frame("model" = c("add.hw", "add.hw.np", "mult.hw", "mult.hw.np", "double.hw.np", "double.hw"),
#             "goodness_of_fit" = c(training_rse_m1, training_rse_m2, training_rse_m3, training_rse_m4, training_rse_m5, training_rse_m6))

model_fit <- data.frame("model" = c("Additive Triple (0.2)", "Additive Triple", "Double (0.2)", "Double", "Mult Triple(0.2)", "Mult Triple"),
            "SSE" = c(training_sse_m1, training_sse_m2, training_sse_m5, training_sse_m6, training_sse_m3, training_sse_m4))

write.csv(model_fit, 'training_sse.csv')
model_fit

```
The additive models are fitting data better than the multiplicative model.


How well does the model predict the validation data?
```{r}
predicted.m1 <- forecast(m1, h = 24)
predicted.m2 <- forecast(m2, h = 24)
predicted.m3 <- forecast(m3, h = 24)
predicted.m4 <- forecast(m4, h = 24)
predicted.m5 <- forecast(m5, h = 24)
predicted.m6 <- forecast(m6, h = 24)


rmse_m1 <- sqrt(mean((predicted.m1$mean - validation_ts[,'Bankruptcy_Rate'])^2))
rmse_m2 <- sqrt(mean((predicted.m2$mean - validation_ts[,'Bankruptcy_Rate'])^2))
rmse_m3 <- sqrt(mean((predicted.m3$mean - validation_ts[,'Bankruptcy_Rate'])^2))
rmse_m4 <- sqrt(mean((predicted.m4$mean - validation_ts[,'Bankruptcy_Rate'])^2))
rmse_m5 <- sqrt(mean((predicted.m5$mean - validation_ts[,'Bankruptcy_Rate'])^2))
rmse_m6 <- sqrt(mean((predicted.m6$mean - validation_ts[,'Bankruptcy_Rate'])^2))

m1 <- HoltWinters(x = brate,alpha = 0.2, beta =  0.2, gamma = 0.2, seasonal = "additive") 
predicted.m1 <- forecast(m1, h = 24)
predicted.m1$mean

# data.frame("model" = c("add.hw", "add.hw.np", "mult.hw", "mult.hw.np", "double.hw"),
            # "prediction" = c(rmse_m1, rmse_m2, rmse_m3, rmse_m4, rmse_m5))

model_predict <- data.frame("Model" = c("Additive Triple (0.2)", "Additive Triple", "Mult Triple (0.2)", "Mult Triple", "Double (0.2)", "Double"), "RMSE" = c(rmse_m1, rmse_m2, rmse_m3, rmse_m4, rmse_m5, rmse_m6))

# model_predict

write.csv(predicted.m1$mean, 'HW.predictions')
```
The additive model also does better in terms of prediction.
```{r}
predicted.m1$mean
```

```{r}
write.csv(predicted.m1, 'hw_forecast.csv')
```


Working with additive model, let's try tuning the parameter (alpha, beta, gamma).

```{r}
m1.1 <- HoltWinters(x = brate, alpha = 0.1, beta =  0.2, gamma = 0.2, seasonal = "add") 
m1.2 <- HoltWinters(x = brate, alpha = 0.5, beta =  0.2, gamma = 0.2, seasonal = "add") 
m1.3 <- HoltWinters(x = brate, alpha = 0.2, beta =  0.1, gamma = 0.2, seasonal = "add") 
m1.4 <- HoltWinters(x = brate, alpha = 0.2, beta =  0.5, gamma = 0.2, seasonal = "add") 
m1.5 <- HoltWinters(x = brate, alpha = 0.2, beta =  0.2, gamma = 0.5, seasonal = "add") 
m1.6 <- HoltWinters(x = brate, alpha = 0.2, beta =  0.2, gamma = 0.1, seasonal = "add") 
m1.7 <- HoltWinters(x = brate, alpha = 0.2, beta =  0.1, gamma = 0.6, seasonal = "add") 

training_rse_m1 <- sum((brate - m1$fitted)^2)
training_rse_m1.1 <- sqrt(sum((brate - m1.1$fitted)^2))
training_rse_m1.2 <- sqrt(sum((brate - m1.2$fitted)^2))
training_rse_m1.3 <- sqrt(sum((brate - m1.3$fitted)^2))
training_rse_m1.4 <- sqrt(sum((brate - m1.4$fitted)^2))
training_rse_m1.5 <- sqrt(sum((brate - m1.5$fitted)^2))
training_rse_m1.6 <- sqrt(sum((brate - m1.6$fitted)^2))
training_rse_m1.7 <- sqrt(sum((brate - m1.7$fitted)^2))


data.frame("model" = c("(0.2, 0.2, 0.2)", "(0.1, 0.2, 0.2)", "(0.5, 0.2, 0.2)", "(0.2, 0.1, 0.2)", "(0.2, 0.5, 0.2)", 
                       "(0.2, 0.2, 0.5)", "(0.2, 0.2, 0.1)", "(0.2, 0.1, 0.6)"),
            "goodness_of_fit" = c(training_rse_m1, training_rse_m1.1, training_rse_m1.2, training_rse_m1.3,
                                  training_rse_m1.4, training_rse_m1.5, training_rse_m1.6, training_rse_m1.7))

```
Not really that useful (only changes in 4th decimal point). Just choose the model with parameters (0.2, 0.2, 0.2).


Ensemble
```{r}
full_ts <- ts(train, start=c(1987,1), end=c(2010,12), frequency = 12)
train_ts <- ts(train[1:264, ], start=c(1987,1), end=c(2008,12), frequency = 12)
validation_ts <- ts(train[265:288, ], start=c(2009,1), end=c(2010,12), frequency = 12)
```

```{r}
unemployment <- train_ts[,'Unemployment_Rate']
house_price <- train_ts[,'House_Price_Index']

```

```{r}
brate <- log(train_ts[,'Bankruptcy_Rate'])
```

```{r}
m2_un_hp <- arima(brate, order = c(2,1,1), seasonal = list(order = c(1,0,1), period = 12),
            xreg = data.frame(unemployment, house_price))
sarimax.m2_un_hp <- forecast(m2_un_hp, h = 24,  xreg = data.frame(validation_ts[,'Unemployment_Rate'], validation_ts[,'House_Price_Index']), level = 95)
```

```{r}
sarimax.fitted <- exp(fitted(m2_un_hp))
```


```{r}
sarimax.pred.exp <- exp(sarimax.m2_un_hp$mean)
```

```{r}
m2p2=VAR(y = data.frame(brate, unemployment, house_price), p = 2)
pred <- predict(m2p2, n.ahead = 24, ci = 0.95)
```

```{r}
var.fitted <- exp(ts(fitted(m2p2)[,'brate'], start=c(1987, 1), end=c(2008, 12), frequency = 12))
```

```{r}
var.pred.exp <- exp(pred$fcst$brate[,'fcst'])
```

```{r}
predictions <- data.frame(sarimax = sarimax.pred.exp, var = var.pred.exp)
```

```{r}
predictions
```


```{r}
ensemble.predictions <- (predictions$sarimax + predictions$var)/2
```


```{r}
ensemble.fitted <- (sarimax.fitted + var.fitted)/2
```

```{r}
plot(ensemble.fitted)
x```

